# stop & remove eventuale container
docker stop mlflow 2>/dev/null || true
docker rm -f mlflow 2>/dev/null || true

# libera porta 5000 se bloccata
sudo fuser -k 5000/tcp 2>/dev/null || true

# (opzionale) svuota la cartella di artifacts/DB locali
rm -rf mlruns && mkdir -p mlruns

docker run -d --name mlflow -p 5000:5000 \
  -v "$(pwd)/mlruns:/mlruns" \
  ghcr.io/mlflow/mlflow:v2.16.0 \
  mlflow server --host 0.0.0.0 --port 5000 \
  --backend-store-uri sqlite:////mlruns/mlflow.db \
  --artifacts-destination file:///mlruns \
  --serve-artifacts


docker logs --tail 50 mlflow


unset MLFLOW_ARTIFACT_URI
export MLFLOW_TRACKING_URI=http://localhost:5000


python - <<'PY'
import mlflow, json
mlflow.set_experiment("check-artifact-uri")
with mlflow.start_run() as run:
    print("RUN ID:", run.info.run_id)
    info = mlflow.get_run(run.info.run_id).info
    print("artifact_uri:", info.artifact_uri)
PY

export MLFLOW_TRACKING_URI=http://localhost:5000
python -m src.models.train_roberta --experiment sentiment_m2

NEW_URI="runs:/7308c35a93ce42f892c69fe99e4e031a/model"
python -m src.models.evaluate --new_model_uri "$NEW_URI" --eval_csv data/holdoutENG.csv --min_improvement 0.0

export MODEL_URI=models:/Sentiment/Production
uvicorn src.serving.app:app --reload --port 8000

--------

mkdir -p data/raw data/incoming artifacts
cp data/holdoutENG.csv data/raw/reference.csv
cp data/holdoutENG.csv data/incoming/2025-11-22.csv

-----

docker compose up -d mlflow airflow


---

df -h
docker system df
du -xh ~ | sort -h | tail -20
du -xh . | sort -h | tail -20

# contenitori/immagini/reti/volumi non usati
docker system prune -af --volumes
# cache builder (layer build)
docker builder prune -af

rm -rf ~/.cache/huggingface
rm -rf ~/.cache/torch

# ATTENZIONE: perderai esperimenti/artifacts locali
docker stop mlflow 2>/dev/null || true
rm -rf mlruns/*
mkdir -p mlruns


docker compose up -d --force-recreate --no-deps airflow
docker logs --tail 100 -f airflow



# il servizio sta ascoltando?
docker compose exec airflow bash -lc "ss -ltnp | grep 8080 || netstat -ltnp | grep 8080"
docker compose exec airflow bash -lc "curl -sS http://localhost:8080 | head -n 10"

docker compose config


docker compose down -v
sudo fuser -k 5000/tcp 2>/dev/null || true

docker compose build airflow airflow-init


docker compose down -v
sudo fuser -k 5000/tcp 2>/dev/null || true
docker compose build airflow airflow-init

# 1) Spegni lo stack corrente (se presente)
docker compose down -v || true

docker ps --filter "publish=5000" --format "{{.ID}} {{.Names}} {{.Ports}}"
docker ps --filter "publish=5000" -q | xargs -r docker stop
docker ps --filter "publish=5000" -q | xargs -r docker rm -f

docker ps -a | grep -i mlflow || true
docker ps -aq -f "name=mlflow" | xargs -r docker rm -f

docker ps --format "table {{.Names}}\t{{.Ports}}\t{{.Status}}"

# Target UP?
curl -fsS http://localhost:9090/-/ready && echo "prometheus ready"

# Elenco target/scrape (deve mostrare state: up)
# 50 richieste /predict
docker compose exec app bash -lc '
python - << "PY"
import requests, random, time
URL="http://localhost:8000/predict"
texts=[
 "I love this product!", "This is terrible.", "Meh, it is fine.",
 "Awesome job!", "Worst experience ever", "Nothing special"
]
for i in range(50):
    t=random.choice(texts)
    try:
        r=requests.post(URL,json={"text":t},timeout=10)
        print(i, r.status_code, r.json())
    except Exception as e:
        print("ERR",e)
    time.sleep(0.2)
PY
'

docker compose exec app bash -lc '
python - << "PY"
import requests, random, time
URL="http://localhost:8000/predict"
texts=[
 "I love this product!", "This is terrible.", "Meh, it is fine.",
 "Awesome job!", "Worst experience ever", "Nothing special"
]
for i in range(50):
    t=random.choice(texts)
    r=requests.post(URL,json={"text":t},timeout=30)
    try:
        print(i, r.status_code, r.json())
    except Exception as e:
        print(i, r.status_code, "BODY:", r.text[:200], "ERR:", e)
    time.sleep(0.2)
PY
'
docker compose logs grafana | tail -n 80

docker compose exec grafana ls -l /etc/grafana/dashboards
apt-get update && apt-get install -y curl
for i in {1..20}; do 
  curl -s -X POST http://localhost:8000/predict \
       -H "Content-Type: application/json" \
       -d '{"text":"I love this!"}'
  echo
done

docker compose logs app | tail -n 50

docker compose exec app bash -lc '
for i in {1..20}; do
  curl -s -X POST http://localhost:8000/predict \
       -H "Content-Type: application/json" \
       -d "{\"text\":\"I love this!\"}"
done
'

docker compose exec pushgateway wget -qO- http://localhost:9091/metrics

curl -s https://glorious-space-trout-44x559vqrjwfj45g-8000.app.github.dev/metrics | head
curl -s http://localhost:8000/metrics | head
curl -s https://glorious-space-trout-44x559vqrjwfj45g-8000.app.github.dev/metrics
docker compose exec pushgateway wget -qO- http://pushgateway:9091/metrics | grep sentiment
