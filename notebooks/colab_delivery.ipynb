{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Colab demo \u2014 MLOps Sentiment",
        "Notebook pronto per Google Colab: clona il repo, installa le dipendenze, addestra il modello, valuta/promuove in MLflow e prova un'inferenza."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Clona il repository\nImposta l'URL del tuo fork pubblico (variabile `REPO_URL`, default gi\u00e0 settato) e clona in `/content`. Se hai gi\u00e0 il repo montato, salta questa cella.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os, pathlib\n",
        "REPO_URL = os.environ.get('REPO_URL', 'https://github.com/<your-account>/MachineInnovatorsInc_ProAI.git')\n",
        "repo_dir = pathlib.Path('/content/MachineInnovatorsInc_ProAI')\n",
        "\n",
        "if not repo_dir.exists():\n",
        "    !git clone $REPO_URL\n",
        "%cd $repo_dir\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Installa le dipendenze",
        "Usa i requisiti del progetto (transformers, scikit-learn, mlflow, ecc.)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import sys, pathlib, os\n",
        "project_root = pathlib.Path.cwd()\n",
        "if not (project_root / 'src').exists():\n",
        "    alt = pathlib.Path('/content/MachineInnovatorsInc_ProAI')\n",
        "    if alt.exists():\n",
        "        project_root = alt\n",
        "        os.chdir(project_root)\n",
        "    else:\n",
        "        raise RuntimeError('Repository non trovato: esegui la cella 1 per clonare e posizionarti nella repo.')\n",
        "else:\n",
        "    os.chdir(project_root)\n",
        "\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.append(str(project_root))\n",
        "\n",
        "!pip install -q -r requirements.txt\n",
        "\n",
        "os.environ.setdefault('MLFLOW_TRACKING_URI', 'file://' + str(project_root/'mlruns'))\n",
        "os.environ.setdefault('REGISTERED_MODEL_NAME', 'Sentiment')\n",
        "\n",
        "print('Working directory:', project_root)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Smoke test di inferenza (Hugging Face)",
        "Usa la pipeline pre-addestrata `cardiffnlp/twitter-roberta-base-sentiment-latest` senza passare da MLflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from src.serving.load_model import predict_fn\n",
        "label, score = predict_fn('I love this course!')\n",
        "print({'label': label, 'score': score})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Addestra e registra una nuova versione in MLflow",
        "Questo step logga una versione del modello nel Model Registry locale (file-based)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "!python -m src.models.train_roberta --experiment sentiment_colab\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Recupera l'ultima versione registrata",
        "Leggiamo dal Model Registry l'ultima versione (stage `None`) per valutarla."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from mlflow.tracking import MlflowClient\n",
        "model_name = os.environ.get('REGISTERED_MODEL_NAME', 'Sentiment')\n",
        "client = MlflowClient(tracking_uri=os.environ['MLFLOW_TRACKING_URI'])\n",
        "versions = client.get_latest_versions(model_name, stages=['None'])\n",
        "if not versions:\n",
        "    versions = client.search_model_versions(f\"name='{model_name}'\")\n",
        "latest = sorted(versions, key=lambda v: int(v.version))[-1]\n",
        "new_model_uri = f\"models:/{model_name}/{latest.version}\"\n",
        "print('new_model_uri =', new_model_uri)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Valuta e promuovi rispetto all'holdout",
        "Usiamo `data/holdout.csv` come set di valutazione. Se il nuovo modello \u00e8 >= del Production (o se Production non esiste) viene promosso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "!python -m src.models.evaluate --new_model_uri $new_model_uri --eval_csv data/holdout.csv --min_improvement 0.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Leggi il modello in Production",
        "Otteniamo la URI del modello con stage `Production` dal Registry e impostiamo `MODEL_URI` per l'inferenza."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from src.utils.mlflow_utils import get_production_model_uri\n",
        "prod_uri = get_production_model_uri(model_name)\n",
        "print('Production URI:', prod_uri)\n",
        "os.environ['MODEL_URI'] = prod_uri or ''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Inferenza usando il modello in Production",
        "Con `MODEL_URI` puntato al registry, `predict_fn` user\u00e0 MLflow; in fallback user\u00e0 Hugging Face."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "label, score = predict_fn('This is a terrible experience')\n",
        "print({'label': label, 'score': score})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) Note utili",
        "- Il registry \u00e8 file-based (`mlruns` nella root): scarica la cartella se vuoi conservarlo.",
        "- Per simulare data drift e triggerare il retrain via Airflow/Grafana, vedi `docs/data_drift_simulation.md`.",
        "- Il flusso di training/valutazione/promozione \u00e8 descritto in `docs/training_and_promotion.md`."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}