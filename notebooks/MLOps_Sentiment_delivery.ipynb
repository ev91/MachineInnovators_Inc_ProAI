{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb90f7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "# URL del repository pubblico\n",
    "REPO_URL = 'https://github.com/ev91/MachineInnovators_Inc_ProAI.git'\n",
    "repo_dir = pathlib.Path('/content/MachineInnovators_Inc_ProAI')\n",
    "\n",
    "if not repo_dir.exists():\n",
    "    print(f\"[*] Clonazione di {REPO_URL}...\")\n",
    "    !git clone $REPO_URL\n",
    "    print(f\"[✓] Repository clonato in {repo_dir}\")\n",
    "else:\n",
    "    print(f\"[*] Repository già presente in {repo_dir}\")\n",
    "\n",
    "os.chdir(repo_dir)\n",
    "print(f\"[✓] Working directory: {repo_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9403b625",
   "metadata": {},
   "source": [
    "## 2) Installa le dipendenze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7659ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "project_root = pathlib.Path.cwd()\n",
    "\n",
    "# Verifica che il repo sia nella working directory\n",
    "if not (project_root / 'src').exists():\n",
    "    alt = pathlib.Path('/content/MachineInnovators_Inc_ProAI')\n",
    "    if alt.exists():\n",
    "        project_root = alt\n",
    "        os.chdir(project_root)\n",
    "    else:\n",
    "        raise RuntimeError('Repository non trovato: esegui la cella precedente per clonare')\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"[*] Installazione dipendenze da {project_root / 'requirements.txt'}...\")\n",
    "!pip install -q -r requirements.txt\n",
    "print(f\"[✓] Dipendenze installate\")\n",
    "\n",
    "# Configurazione MLflow\n",
    "os.environ['MLFLOW_TRACKING_URI'] = f'file://{project_root / \"mlruns\"}'\n",
    "os.environ['REGISTERED_MODEL_NAME'] = 'Sentiment'\n",
    "\n",
    "print(f\"[✓] MLflow tracking URI: {os.environ['MLFLOW_TRACKING_URI']}\")\n",
    "print(f\"[✓] Model name: {os.environ['REGISTERED_MODEL_NAME']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1db9591",
   "metadata": {},
   "source": [
    "## 3) Demo: Inferenza con il modello HuggingFace\n",
    "\n",
    "Usiamo il modello pre-addestrato `cardiffnlp/twitter-roberta-base-sentiment-latest` per fare una predizione rapida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffac944",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.serving.load_model import predict_fn\n",
    "\n",
    "# Test su diversi testi\n",
    "test_texts = [\n",
    "    \"I absolutely love this product!\",\n",
    "    \"This is just okay, nothing special.\",\n",
    "    \"Terrible experience, would not recommend.\",\n",
    "]\n",
    "\n",
    "print(\"[*] Predizioni usando il modello HuggingFace:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for text in test_texts:\n",
    "    label, score = predict_fn(text)\n",
    "    print(f\"Text: {text[:50]:50s} | Label: {label:8s} | Score: {score:.4f}\")\n",
    "\n",
    "print(\"[✓] Inferenza completata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fb1f87",
   "metadata": {},
   "source": [
    "## 4) Addestra una nuova versione del modello\n",
    "\n",
    "Questo step registra una nuova versione del modello nel MLflow Model Registry (file-based)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a645724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[*] Avvio training...\")\n",
    "!python -m src.models.train_roberta --experiment sentiment_colab\n",
    "print(\"[✓] Training completato\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a5043f",
   "metadata": {},
   "source": [
    "## 5) Recupera l'ultima versione registrata dal Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7cb4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "model_name = os.environ.get('REGISTERED_MODEL_NAME', 'Sentiment')\n",
    "tracking_uri = os.environ['MLFLOW_TRACKING_URI']\n",
    "\n",
    "client = MlflowClient(tracking_uri=tracking_uri)\n",
    "\n",
    "# Recupera tutte le versioni\n",
    "all_versions = client.search_model_versions(f\"name='{model_name}'\")\n",
    "\n",
    "if not all_versions:\n",
    "    raise RuntimeError(f\"Nessuna versione trovata per il modello '{model_name}'\")\n",
    "\n",
    "# Prendi la versione più recente\n",
    "latest = sorted(all_versions, key=lambda v: int(v.version))[-1]\n",
    "new_model_uri = f\"models:/{model_name}/{latest.version}\"\n",
    "\n",
    "print(f\"[✓] Ultime versioni registrate:\")\n",
    "for v in sorted(all_versions[-3:], key=lambda x: int(x.version), reverse=True):\n",
    "    print(f\"  - Version {v.version}: stage={v.current_stage}\")\n",
    "\n",
    "print(f\"[✓] Usando versione: {new_model_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2e784f",
   "metadata": {},
   "source": [
    "## 6) Valuta e promuovi a Production\n",
    "\n",
    "Usiamo `data/holdout.csv` come set di valutazione. Se il nuovo modello è >= della versione in Production (o se nessuno è in Production), viene promosso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2658e94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[*] Valutazione del modello e promozione a Production...\")\n",
    "!python -m src.models.evaluate --new_model_uri $new_model_uri --eval_csv data/holdout.csv --min_improvement 0.0\n",
    "print(\"[✓] Valutazione e promozione completate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec4a8b4",
   "metadata": {},
   "source": [
    "## 7) Carica il modello in Production dal registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d31472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.mlflow_utils import get_production_model_uri\n",
    "\n",
    "prod_uri = get_production_model_uri(model_name)\n",
    "\n",
    "if prod_uri:\n",
    "    os.environ['MODEL_URI'] = prod_uri\n",
    "    print(f\"[✓] Production URI trovata: {prod_uri}\")\n",
    "else:\n",
    "    os.environ['MODEL_URI'] = ''\n",
    "    print(f\"[!] Production URI non trovata, fallback a HuggingFace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96d927e",
   "metadata": {},
   "source": [
    "## 8) Inferenza usando il modello in Production\n",
    "\n",
    "Ora usiamo il modello registrato in Production (se disponibile) altrimenti fallback su HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1303f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload predict_fn per utilizzare il nuovo MODEL_URI\n",
    "import importlib\n",
    "import src.serving.load_model\n",
    "importlib.reload(src.serving.load_model)\n",
    "from src.serving.load_model import predict_fn\n",
    "\n",
    "print(f\"[*] Predizioni usando MODEL_URI={os.environ.get('MODEL_URI', 'None (fallback HF)')}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "test_texts = [\n",
    "    \"This is amazing! Best service ever!\",\n",
    "    \"Not the best, could be better.\",\n",
    "    \"Absolutely horrible, never again!\",\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    label, score = predict_fn(text)\n",
    "    print(f\"Text: {text[:50]:50s} | Label: {label:8s} | Score: {score:.4f}\")\n",
    "\n",
    "print(\"[✓] Inferenza completata\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
