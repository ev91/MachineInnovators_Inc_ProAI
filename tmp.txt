# Stop e pulizia porte
docker compose down -v
sudo fuser -k 5000/tcp 2>/dev/null || true

# Verifica sintassi compose
docker compose config

# Avvia SOLO MLflow e verifica che ascolti sulla 5000
docker compose up -d mlflow
docker compose logs -f mlflow   # esci con Ctrl+C quando vedi "Listening at: http://0.0.0.0:5000"

# Inizializza Airflow (one-off) → deve terminare con successo
docker compose run --rm airflow-init

# Avvia Airflow (webserver + scheduler) e attendi la riga di listening
docker compose up -d airflow
docker compose logs -f airflow  # attendi "Listening at: http://0.0.0.0:8080"



_______
docker compose down -v
sudo fuser -k 5000/tcp 2>/dev/null || true

docker compose up -d mlflow
docker compose run --rm airflow-init
docker compose up -d airflow
docker compose logs -f airflow   # attendi “Listening at: http://0.0.0.0:8080”

docker compose up -d --force-recreate airflow




# esistono i file dati?
docker compose exec airflow bash -lc "ls -l /opt/airflow/data/holdout.csv /opt/airflow/data/raw || true"

# prepara reference se manca
docker compose exec airflow bash -lc "mkdir -p /opt/airflow/data/raw && cp -f /opt/airflow/data/holdout.csv /opt/airflow/data/raw/reference.csv && ls -l /opt/airflow/data/raw/reference.csv"

# prova lo script Evidently a mano (stessi path del DAG)
docker compose exec airflow bash -lc "mkdir -p /opt/airflow/artifacts && python -m src.monitoring.drift_report --reference /opt/airflow/data/raw/reference.csv --current /opt/airflow/data/holdout.csv --out /opt/airflow/artifacts"
# ← se stampa uno stacktrace (es. download HF fallito), è il motivo.

# verifica se i file ora ci sono
docker compose exec airflow bash -lc "ls -l /opt/airflow/artifacts || true"

