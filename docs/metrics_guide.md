# Guida alle metriche esposte

## üìä Metriche dell'API Serving (FastAPI)

### Metriche di Traffic e Performance
- **`app_requests_total`** (Counter): Conteggio totale delle richieste a `/predict`. 
  - Utile per monitorare il volume di utilizzo nel tempo
  - Incrementato per ogni richiesta (successo o fallimento)

- **`app_errors_total`** (Counter): Conteggio totale degli errori durante l'inferenza.
  - Se cresce in parallelo alle richieste (`app_requests_total`), la qualit√† del servizio sta degradando
  - Verificare i log per identificare cause di errore

- **`app_request_latency_seconds`** (Histogram): Latenza end-to-end del `/predict` endpoint.
  - Traccia la durata completa da richiesta a risposta
  - In Grafana i pannelli p50/p90 usano:
    ```promql
    histogram_quantile(0.5, sum(rate(app_request_latency_seconds_bucket[5m])) by (le))  # p50 (mediana)
    histogram_quantile(0.9, sum(rate(app_request_latency_seconds_bucket[5m])) by (le))  # p90
    ```
  - **Perch√© p50/p90?** La media nasconde code lunghe. P50 mostra la latenza tipica, P90 cattura gli outlier che impattano l'esperienza utente.
  - **Valori attesi**: dopo warm-up, p50 < 500ms, p90 < 2s (dipende da hardware)

### Metriche di Sentiment
- **`app_sentiment_predictions_total`** (Counter with label `sentiment_label`): Conteggio delle predizioni per etichetta sentiment.
  - Labels: `sentiment_label ‚àà {positive, neutral, negative}`
  - Esempio query Grafana per distribuzione:
    ```promql
    sum(rate(app_sentiment_predictions_total[5m])) by (sentiment_label)
    ```
  - **Utilit√†**: Permette di monitorare se il sentiment della community sta cambiando nel tempo
  - Se il `positive` crolla improvvisamente, potrebbe indicare un problema reputazionale che il DAG di drift non ha ancora catturato
  
### Monitoraggio Data Drift
- **`data_drift_flag`** (Gauge, 0/1): Segnale binario di data drift.
  - Inizializzato a 0 all'avvio della app
  - Aggiornato dal DAG Airflow via Pushgateway quando esegue la drift detection
  - **Valore 0**: nessun drift, dati coerenti con baseline
  - **Valore 1**: drift rilevato, trigger automatico del retraining

---

## ü§ñ Metriche del Modello (da Airflow)

Dopo ogni run del task `evaluate_and_promote` nel DAG, vengono pushate a Prometheus le metriche di performance del modello:

- **`model_f1_score`** (Gauge with labels `model_name`, `model_version`): F1-score macro (media tra le 3 classi).
  - Range: 0.0‚Äì1.0
  - Calcolato su `data/holdout.csv` durante la fase di valutazione
  - Traccia come la qualit√† del modello evolve attraverso le versioni
  - **Alert suggerito**: Se scende sotto 0.75, investigare possibile data shift

- **`model_accuracy`** (Gauge with labels `model_name`, `model_version`): Accuracy globale.
  - Range: 0.0‚Äì1.0
  - Percentuale di predizioni corrette su tutto il dataset di valutazione
  - Utile come metrica complementare a F1 (soprattutto se le classi sono sbilanciate)

**Come vengono generate:**
1. DAG esegue `src.models.evaluate` con il nuovo modello
2. Evaluate calcola F1 e accuracy su holdout set
3. Se promuove a Production, DAG chiama `src.monitoring.push_model_metrics`
4. Metriche vengono pushate al Pushgateway con `job=model_performance`
5. Prometheus scrappa il Pushgateway e rende disponibile le metriche a Grafana

---

## üîÑ Flusso Prometheus/Pushgateway/Grafana

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  FastAPI App             ‚îÇ
‚îÇ  - /predict endpoint    ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ Espone su /metrics (scrape ogni 15s) ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  - Metriche API         ‚îÇ                                              ‚îÇ
‚îÇ  - app_sentiment_*      ‚îÇ                                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                             ‚îÇ
                                                                          ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                             ‚îÇ
‚îÇ  Airflow DAG             ‚îÇ                                             ‚îÇ
‚îÇ  - evaluate_and_promote ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ Push model_f1_score, accuracy ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  - compute_drift        ‚îÇ      al Pushgateway (porta 9091)       ‚îÇ   ‚îÇ
‚îÇ  - push_model_metrics   ‚îÇ                                        ‚îÇ   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                       ‚îÇ   ‚îÇ
                                                                   ‚îÇ   ‚îÇ
                                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                         ‚îÇ   Prometheus (port 9090)          ‚îÇ
                                         ‚îÇ   - Scrappa app:/metrics          ‚îÇ
                                         ‚îÇ   - Scrappa pushgateway:9091      ‚îÇ
                                         ‚îÇ   - Fonde tutte le metriche       ‚îÇ
                                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                           ‚îÇ
                                                           ‚îÇ Query (ogni 10s)
                                                           ‚îÇ
                                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                         ‚îÇ   Grafana (port 3000)              ‚îÇ
                                         ‚îÇ   - Dashboard: MLOps ‚Äì Sentiment   ‚îÇ
                                         ‚îÇ     Analysis Monitoring            ‚îÇ
                                         ‚îÇ   - Panels: Traffic, Sentiment,    ‚îÇ
                                         ‚îÇ     Performance, Drift            ‚îÇ
                                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Step-by-step:**
1. **FastAPI app**: Espone metriche Prometheus su `/metrics` in formato standard (Prometheus text format)
   - Prometheus scrappa questo endpoint ogni 15 secondi (job `app`)
   - Metriche include: richieste, errori, latenza, sentiment predictions

2. **Airflow DAG**: Durante il run di retraining, il task `evaluate_and_promote` 
   - Calcola F1/accuracy nuovo modello
   - Chiama `src.monitoring.push_model_metrics` per pushare le metriche
   - Le metriche vengono inviate al **Pushgateway** (porta 9091)

3. **Pushgateway**: Riceve le metriche e le espone per Prometheus
   - Prometheus ha un job dedicato per scrappare il Pushgateway
   - Unisce le metriche dal Pushgateway con quelle dall'app

4. **Grafana**: Legge tutte le metriche da Prometheus
   - Dashboard `MLOps ‚Äì Sentiment Analysis Monitoring` visualizza:
     - Request rate e error rate
     - Latency percentili
     - Sentiment distribution (pie chart)
     - Model performance (F1 & accuracy timeline)
     - Data drift flag timeline
   - Auto-refresh ogni 10 secondi

---

## üìà Pannelli Principali del Dashboard Grafana

### 1. **Request Rate** (`üìä API Request Rate`)
- Query: `rate(app_requests_total[1m])`
- **Cosa guardare:**
  - Se √® piatto ‚Üí non c'√® traffico (possibile outage)
  - Se sale improvvisamente ‚Üí burst di traffico
  - Se cala drasticamente ‚Üí possibile downtime o problem nell'app
- **Target sano**: Dipende dal use case, ma dovrebbe essere consistente

### 2. **Error Rate** (`‚ö†Ô∏è API Error Rate`)
- Query: `rate(app_errors_total[1m]) / rate(app_requests_total[1m]) * 100`
- **Cosa guardare:**
  - < 0.5% √® buono
  - 0.5% ‚Äì 2% √® accettabile (possibili problemi di rete)
  - > 2% indica problemi seri (controllare log app)
- **Cause comuni**: Modello non caricato, encoding issue, memoria esaurita

### 3. **Latency (p50/p90)** (`‚è±Ô∏è API Latency`)
- Queries: `histogram_quantile(0.5|0.9, ...)`
- **Cosa guardare:**
  - **p50** (mediana) = latenza tipica ‚Üí dovrebbe essere bassa e stabile
  - **p90** (90¬∞ percentile) = latenza dei casi lenti ‚Üí accettabile se < 3x la p50
  - Se p90 cresce mentre p50 resta basso ‚Üí code di attesa
  - Se entrambi salgono ‚Üí possibile sobraccarico o slow inference
- **Azioni**:
  - Aumentare CPU/GPU
  - Implementare caching
  - Scalare orizzontalmente

### 4. **Sentiment Distribution** (`üí≠ Sentiment Distribution`)
- Query: `sum(rate(app_sentiment_predictions_total[5m])) by (sentiment_label)`
- **Cosa guardare**:
  - Proporzione di positive/neutral/negative nel tempo
  - Se il `positive` crolla ‚Üí possibile crisi reputazionale
  - Se il `negative` sale ‚Üí sentiment pubblico sta peggiorando
  - Cambio drastico nella distribuzione ‚Üí possibile shift nei dati
- **Utilit√† per valutatori**: **Mostra che il sistema sta tracciando il sentiment** come richiesto dalla traccia

### 5. **Model Performance (F1 & Accuracy)** (`üéØ Model Performance`)
- Queries: `model_f1_score{...}`, `model_accuracy{...}`
- **Cosa guardare**:
  - Linee dovrebbero restare stabili o salire (mai scendere significativamente)
  - Se scende ‚Üí possibile data drift non catturato dai controlli
  - Jumping points = momenti di retraining + promozione
- **Azioni se scende**:
  - Verificare il dataset di training
  - Controllare i report di drift in `artifacts/`
  - Abbassare la soglia di drift per trigger pi√π frequente

### 6. **Data Drift Timeline** (`üìâ Data Drift Timeline`)
- Query: `data_drift_flag`
- **Cosa guardare**:
  - Quando il valore salta a 1 ‚Üí drift rilevato, retraining triggerato
  - Dovrebbe tornare a 0 dopo il retraining (o rimane 1 se il drift persiste)
  - Frequenza dei picchi = frequenza del retraining
- **Interpretazione**:
  - Picchi rari (< 1 volta a settimana) ‚Üí dati stabili, buon segno
  - Picchi frequenti (> 1 volta al giorno) ‚Üí dati instabili, possibile problema upstream

---

## üîç Come Diagnosticare Problemi

### "L'error rate sta salendo"
```bash
# 1. Controlla i log della app
docker logs machineinnovatorsinc_proai-app-1 | tail -50

# 2. Verifica la disponibilit√† del modello
curl http://localhost:8000/health

# 3. Prova a fare una predizione manuale
curl -X POST http://localhost:8000/predict \
  -H 'Content-Type: application/json' \
  -d '{"text": "test"}'
```

### "Il sentiment √® cambiato drasticamente"
```bash
# 1. Controlla il report di drift
cat artifacts/drift_report.json | jq '.'

# 2. Verifica il flag di drift in Prometheus
curl "http://localhost:9090/api/v1/query?query=data_drift_flag"

# 3. Guarda i log del DAG di drift detection
docker logs machineinnovatorsinc_proai-airflow-1 | grep -i drift
```

### "Il modello F1 √® sceso"
```bash
# 1. Controlla quale versione √® in Production
curl http://localhost:5000/api/2.0/model-versions | jq '.[] | select(.stage == "Production")'

# 2. Guarda le metriche della versione precedente
curl http://localhost:5000/api/2.0/registered-models/Sentiment | jq '.latest_versions'

# 3. Leggi il report di valutazione
cat artifacts/eval_report.txt  # se esiste
```

---

## ‚úÖ Verifiche Rapide da Terminale

### Query Prometheus via REST API
```bash
# Ultimo valore di F1 score
curl -s "http://localhost:9090/api/v1/query?query=model_f1_score" | jq '.data.result'

# Ultimo valore di drift flag
curl -s "http://localhost:9090/api/v1/query?query=data_drift_flag" | jq '.data.result'

# Request rate (ultime 5 minuti)
curl -s "http://localhost:9090/api/v1/query?query=rate(app_requests_total[5m])" | jq '.data.result'
```

### Sample delle metriche esposte dall'app
```bash
curl http://localhost:8000/metrics | head -30
```

### Verifica che Prometheus sta scrappando
```bash
# Accedi a Prometheus UI
open http://localhost:9090

# Vai su Status ‚Üí Targets
# Dovresti vedere:
# - app:8000 (UP)
# - pushgateway:9091 (UP)
```

---

## üìù Note per Valuatori/Sviluppatori

Questa documentazione supporta i **requisiti della traccia d'esame**:
- ‚úÖ **Monitoraggio Continuo della Reputazione**: Sentiment distribution panel + sentiment predictions timeline
- ‚úÖ **Model Performance Tracking**: F1/accuracy panels aggiornati dopo ogni retraining
- ‚úÖ **Data Drift Detection Visualization**: Drift flag timeline + reports in `artifacts/`
- ‚úÖ **System Health Monitoring**: Request rate, error rate, latency (p50/p90)

Tutti i pannelli sono configurati per auto-refresh ogni 10 secondi, permettendo **osservazione in tempo reale** dei modelli e della reputazione online dell'azienda.
